# Data Efficiency

–ö–æ–¥ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å –æ–±—É—á–µ–Ω–∏–µ–º BERT –º–æ–¥–µ–ª–∏ –Ω–∞ 10% –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞

## Features

- üöÄ Train ModernBERT models with data selection strategies
- üìä Automatic checkpoint saving during training
- üîç Comprehensive model evaluation with metrics and visualizations
- üìà TensorBoard integration for training monitoring

## Quick Start

### Installation

```bash
uv sync
```

### Download Dataset

```bash
uv run download_dataset
```

### Training

```bash
python -m data_efficiency.run
```
Add here path to config as `--config=my_filepath` if want to use custom model training or data selection parameters.

### Evaluation

Evaluate a trained model:

```bash
uv run evaluate -c checkpoints/my_run/best/model.pt
```
Add here path to config as `--config=my_filepath` if want to use custom model evaluation parameters.

For more details on evaluation, see [EVALUATION_GUIDE.md](EVALUATION_GUIDE.md).

## Hyperparameter Tuning

For the "all" strategy (training on the full dataset), automatic hyperparameter tuning is available before the main training.

### Enabling Tuning

Add to your configuration file:

```json
{
  "strategy_name": "all",
  "enable_hyperparameter_tuning": true,
  "warmup_epochs": 2,
  "tuning_n_iterations": 25,
  "tuning_sample_size": 0.15,
  "tuning_metric": "val_loss"
}
```

### What Tuning Does

1. **Finds optimal batch size** - determines the maximum batch size that fits in memory (binary search)
2. **Tunes hyperparameters** - uses Random Search to find optimal:
   - Model dropout (0.1 - 0.5)
   - Learning rate (1e-5 - 1e-4)
   - Weight decay (0.0, 0.01, 0.1)
   - Optimizer betas (various options)

Tuning is performed on a small sample from the train dataset (15% by default), which serves as additional regularization and avoids overfitting on the validation set.

After tuning, the model is recreated with optimal parameters, weights are reset, and main training begins.

### Configuration Parameters

- `enable_hyperparameter_tuning` (bool): enable tuning (default: False)
- `warmup_epochs` (int): number of epochs per tuning iteration (default: 2)
- `tuning_n_iterations` (int): number of random combinations to try (default: 25)
- `tuning_sample_size` (float): fraction of train dataset for tuning, 0.15 = 15% (default: 0.15)
- `tuning_metric` (str): metric for selecting best parameters - "val_loss" or "val_accuracy" (default: "val_loss")

Optional parameters for customizing ranges:
- `dropout_range` (List[float]): [min, max] for dropout (default: [0.1, 0.5])
- `lr_range` (List[float]): [min, max] for learning rate (default: [1e-5, 1e-4])
- `weight_decay_options` (List[float]): list of weight_decay values (default: [0.0, 0.01, 0.1])
- `betas_options` (List[List[float]]): list of tuples for betas (default: [[0.9, 0.999], [0.95, 0.999], [0.9, 0.99]])

Example configuration with tuning: `configs/train_config_with_tuning.json`

## ClearML Integration

–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ClearML –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:

1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:
```bash
CLEARML_API_ACCESS_KEY=your_access_key_here
CLEARML_API_SECRET_KEY=your_secret_key_here
```

2. –ü–æ–ª—É—á–∏—Ç–µ –∫—Ä–µ–¥—ã –∏–∑ ClearML: https://app.clear.ml/settings/workspace-configuration

3. –í–∫–ª—é—á–∏—Ç–µ ClearML –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: `"use_clearml": true`

## RunPod Setup

–î–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ RunPod —Å–º. –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é: [RUNPOD_SETUP.md](RUNPOD_SETUP.md)

## Project Structure

```
data-efficiency/
‚îú‚îÄ‚îÄ src/data_efficiency/
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuration classes
‚îÇ   ‚îú‚îÄ‚îÄ data.py            # Dataset handling
‚îÇ   ‚îú‚îÄ‚îÄ model.py           # ModernBERT model wrapper
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py         # Training pipeline
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py        # Evaluation pipeline
‚îÇ   ‚îú‚îÄ‚îÄ run.py             # Training script
‚îÇ   ‚îú‚îÄ‚îÄ strategies/        # Data selection strategies
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Utility functions
‚îú‚îÄ‚îÄ checkpoints/           # Saved model checkpoints
‚îú‚îÄ‚îÄ artifacts/             # Evaluation results
‚îú‚îÄ‚îÄ data/                  # Dataset cache
‚îî‚îÄ‚îÄ runs/                  # TensorBoard logs
```
